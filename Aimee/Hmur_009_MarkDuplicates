#!/bin/bash -l

#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --mem=200G
#SBATCH --time=1-0:00:00
#SBATCH --output=/rhome/auyeh/bigdata/H_mur/results/Hmur_009_MarkDuplicates.stdout
#SBATCH --mail-user=auyeh002@ucr.edu
#SBATCH --mail-type=ALL
#SBATCH --job-name="mrkdup+index"
#SBATCH -p highmem 	 #Options:  intel, batch, highmem (200 Gb memory), gpu, short (jobs with wall time of 2 h) check with squeue -p PARTITIONNAME

module load picard/2.18.3

#### mark duplicates using picard

##test to see if file path works for picard
#java -jar /opt/linux/centos/7.x/x86_64/pkgs/picard/2.18.3/lib/picard.jar -h
cd /rhome/auyeh/bigdata/H_mur/results/aligned/


java -jar /opt/linux/centos/7.x/x86_64/pkgs/picard/2.18.3/lib/picard.jar MarkDuplicates INPUT=/rhome/auyeh/bigdata/H_mur/results/aligned/hmur_paired_sorted_merged_final.bam OUTPUT=hmur_marked_duplicates_index.bam METRICS_FILE=hmur_marked_dup_metrics_index.txt CREATE_INDEX=true TAGGING_POLICY=All
